# -*- coding: utf-8 -*-
from odoo import http
from odoo.http import request
import logging
import pandas as pd
from datetime import datetime
from dateutil.relativedelta import relativedelta

_logger = logging.getLogger(__name__)



class WorkProgramDashboardController(http.Controller):

    @http.route('/dashboard/current_employee_info', type='json', auth='user', methods=['GET', 'POST'], csrf=False)
    def get_current_employee_info(self, **kw):
        """
        Retourne les infos de l'employ√© li√© √† l'utilisateur connect√© :
        - id, name
        - department: {id, name} (None si pas de d√©partement)
        - image_url: URL de l'image de l'employ√© (ou placeholder)
        - role: R√¥le prioritaire ('Administrateur', 'Manager', 'Employ√©')
        """
        try:
            user = request.env.user
            _logger.info(f"R√©cup√©ration info employ√© pour user: {user.login} ({user.name})")

            # R√©cup√©ration de l'employ√© li√© √† l'utilisateur connect√©
            employee = request.env['hr.employee'].sudo().search([('user_id', '=', user.id)], limit=1)

            if not employee:
                _logger.warning(f"Aucun employ√© associ√© pour l'utilisateur {user.name} (id={user.id})")
                return {
                    'error': True,
                    'message': "Aucun employ√© associ√© √† cet utilisateur.",
                    'employee': None
                }

            # R√©cup√©ration des informations de base
            emp_id = employee.id
            emp_name = employee.name or ''
            dept = employee.department_id.sudo() if employee.department_id else None
            dept_info = {'id': dept.id, 'name': dept.name} if dept else None

            # URL de l'image
            image_url = f"/web/image/hr.employee/{emp_id}/avatar_128" if emp_id else "/web/static/src/img/placeholder.png"

            # D√©termination du r√¥le prioritaire
            if user.has_group('workprogramm.workprogramm_group_admin'):
                role = "Administrateur"
            elif user.has_group('workprogramm.workprogramm_group_manager'):
                role = "Manager"
            elif user.has_group('workprogramm.workprogramm_group_user_limited'):
                role = "Employ√©"
            else:
                role = "Employ√©"  # Valeur par d√©faut si aucun r√¥le sp√©cifique

            _logger.info(f"‚úÖ Employ√© trouv√© : {emp_name}, D√©partement : {dept_info['name'] if dept_info else 'Aucun'}, R√¥le : {role}")

            return {
                'error': False,
                'employee': {
                    'id': emp_id,
                    'name': emp_name,
                    'department': dept_info,
                    'image_url': image_url,
                    'role': role
                }
            }

        except Exception as e:
            _logger.exception("Erreur lors de la r√©cup√©ration des infos employ√©")
            return {
                'error': True,
                'message': str(e),
                'employee': None
            }

   
    def _apply_security_filter(self, df):
        """
        Filtre le DataFrame selon les droits d'acc√®s de l'utilisateur :
        - Admin ou Manager : acc√®s √† toutes les donn√©es.
        - User (standard ou limit√©) : acc√®s aux enregistrements o√π il est responsible_id ou dans support_ids.
        """
        user = request.env.user
        _logger.info(f"Application du filtre de s√©curit√© pour l'utilisateur : {user.name}")
    
        # V√©rifier si l'utilisateur est Admin ou Manager
        if user.has_group('workprogramm.workprogramm_group_admin') or user.has_group('workprogramm.workprogramm_group_manager'):
            _logger.info(f"üëë Utilisateur {user.name} (Admin/Manager) - acc√®s √† toutes les donn√©es")
            return df
    
        # Trouver l'employ√© associ√©
        employee = request.env['hr.employee'].sudo().search([('user_id', '=', user.id)], limit=1)
        if not employee:
            _logger.warning(f"‚ö†Ô∏è Utilisateur {user.name} n'a pas d'employ√© associ√©")
            return pd.DataFrame()

        # Utilisateur standard ou limit√© : acc√®s aux t√¢ches o√π il est responsible_id ou dans support_ids
        _logger.info(f"üë§ Utilisateur {user.name} - acc√®s aux donn√©es o√π il est responsable ou support")
        if 'responsible_id' in df.columns and 'support_ids' in df.columns:
            return df[
                (df['responsible_id'] == employee.id) |
                (df['support_ids'].apply(lambda x: employee.id in x if isinstance(x, list) else False))
            ]
        elif 'responsible_id' in df.columns:
            return df[df['responsible_id'] == employee.id]
        return pd.DataFrame()
    
    @http.route('/dashboard/work_program_projects_count', type='json', auth='user', methods=['POST'], csrf=False)
    def get_work_program_projects_count(self, date_from=None, date_to=None, department_id=None, responsible_id=None, project_id=None):
        """
        R√©cup√®re le nombre distinct de projets avec filtres date, d√©partement et responsable
        """
        try:
            _logger.info(
                f"D√©but de get_work_program_projects_count avec filtres: "
                f"date_from={date_from}, date_to={date_to}, dept={department_id}, resp={responsible_id}"
            )

            # R√©cup√©ration de toutes les t√¢ches
            tasks = request.env['work.program'].sudo().search([])
            _logger.info(f"Trouv√© {len(tasks)} t√¢ches au total")

            if not tasks:
                return {'total_projects': 0, 'error': False}

            # Pr√©paration des donn√©es
            task_data_list = []
            for task in tasks:
                task_data_list.append({
                    'id': task.id,
                    'assignment_date': task.assignment_date if task.assignment_date else None,
                    'department_id': task.responsible_id.department_id.id if task.responsible_id and task.responsible_id.department_id else None,
                    'support_ids': [emp.id for emp in task.support_ids] if task.support_ids else [],
                    'responsible_id': task.responsible_id.id if task.responsible_id else None,
                    'project_id': task.project_id.id if task.project_id else None,
                })

            df = pd.DataFrame(task_data_list)

            if df.empty:
                return {'total_projects': 0, 'error': False}
            
            df = self._apply_security_filter(df)

            # Application des filtres
            filtered_df = self._apply_date_filters(df, date_from, date_to, department_id, responsible_id,project_id)

            if filtered_df.empty:
                _logger.info("Aucune t√¢che apr√®s filtres - retour de 0 projets")
                return {'total_projects': 0, 'error': False}

            # Calcul du nombre distinct de projets
            nb_projets = filtered_df['project_id'].nunique()
            _logger.info(f"Nombre de projets distincts apr√®s filtres: {nb_projets}")

            return {
                'total_projects': nb_projets,
                'error': False
            }

        except Exception as e:
            _logger.error(f"Erreur dans get_work_program_projects_count: {str(e)}", exc_info=True)
            return {
                'error': True,
                'message': str(e),
                'total_projects': 0
            }
            
    @http.route('/dashboard/work_program_count', type='json', auth='user', methods=['POST'], csrf=False)
    def get_work_program_count(self, date_from=None, date_to=None, department_id=None, responsible_id=None,project_id=None):
        """
        R√©cup√®re le nombre total de t√¢ches avec filtres date, d√©partement et responsable
        """
        try:
            _logger.info(
                f"D√©but de get_work_program_count avec filtres: "
                f"date_from={date_from}, date_to={date_to}, dept={department_id}, resp={responsible_id}"
            )

            # R√©cup√©ration de toutes les t√¢ches
            tasks = request.env['work.program'].sudo().search([])
            _logger.info(f"Trouv√© {len(tasks)} t√¢ches au total")

            if not tasks:
                return {'total_tasks': 0, 'error': False}

            # Pr√©paration des donn√©es
            task_data_list = []
            for task in tasks:
                task_data_list.append({
                    'id': task.id,
                    'assignment_date': task.assignment_date if task.assignment_date else None,
                    'project_id': task.project_id.id if task.project_id else None,
                    'department_id': task.responsible_id.department_id.id if task.responsible_id and task.responsible_id.department_id else None,
                    'responsible_id': task.responsible_id.id if task.responsible_id else None,
                    'support_ids': [emp.id for emp in task.support_ids] if task.support_ids else [],
                })

            df = pd.DataFrame(task_data_list)

            if df.empty:
                return {'total_tasks': 0, 'error': False}
            
            df = self._apply_security_filter(df)

            # Application des filtres
            filtered_df = self._apply_date_filters(df, date_from, date_to, department_id, responsible_id,project_id)

            if filtered_df.empty:
                _logger.info("Aucune t√¢che apr√®s filtres - retour de 0 t√¢ches")
                return {'total_tasks': 0, 'error': False}

            # Calcul du nombre total de t√¢ches
            total_tasks = len(filtered_df)
            _logger.info(f"Nombre de t√¢ches apr√®s filtres: {total_tasks}")

            return {
                'total_tasks': total_tasks,
                'error': False
            }

        except Exception as e:
            _logger.error(f"Erreur dans get_work_program_count: {str(e)}", exc_info=True)
            return {
                'error': True,
                'message': str(e),
                'total_tasks': 0
            }
            
    @http.route('/dashboard/work_program_valid', type='json', auth='user', methods=['POST'], csrf=False)
    def get_work_program_valid_count(self, date_from=None, date_to=None, department_id=None, responsible_id=None,project_id=None):
        """
        R√©cup√®re le nombre total de t√¢ches valid√©es avec filtres date, d√©partement et responsable
        """
        try:
            _logger.info(
                f"D√©but de get_work_program_count avec filtres: "
                f"date_from={date_from}, date_to={date_to}, dept={department_id}, resp={responsible_id}"
            )

            # R√©cup√©ration de toutes les t√¢ches
            tasks = request.env['work.program'].sudo().search([])
            _logger.info(f"Trouv√© {len(tasks)} t√¢ches au total")

            if not tasks:
                return {'tasks_valid': 0, 'error': False}

            # Pr√©paration des donn√©es
            task_data_list = []
            for task in tasks:
                task_data_list.append({
                    'id': task.id,
                    'assignment_date': task.assignment_date if task.assignment_date else None,
                    'project_id': task.project_id.id if task.project_id else None,
                    'department_id': task.responsible_id.department_id.id if task.responsible_id and task.responsible_id.department_id else None,
                    'responsible_id': task.responsible_id.id if task.responsible_id else None,
                    'support_ids': [emp.id for emp in task.support_ids] if task.support_ids else [],
                    'state': task.state  # Pour filtrer les t√¢ches valid√©es
                })

            df = pd.DataFrame(task_data_list)

            if df.empty:
                return {'tasks_valid': 0, 'error': False}
            
            df = self._apply_security_filter(df)

            # Filtrage des t√¢ches valid√©es
            df_valid = df[df['state'] == 'validated']

            if df_valid.empty:
                _logger.info("Aucune t√¢che valid√©e apr√®s filtrage")
                return {'tasks_valid': 0, 'error': False}

            # Application des filtres existants
            filtered_df = self._apply_date_filters(df_valid, date_from, date_to, department_id, responsible_id,project_id)

            if filtered_df.empty:
                _logger.info("Aucune t√¢che valid√©e apr√®s filtres suppl√©mentaires")
                return {'tasks_valid': 0, 'error': False}

            # Calcul du nombre total de t√¢ches valid√©es
            tasks_valid = len(filtered_df)
            _logger.info(f"Nombre de t√¢ches valid√©es apr√®s filtres: {tasks_valid}")

            return {
                'tasks_valid': tasks_valid,
                'error': False
            }

        except Exception as e:
            _logger.error(f"Erreur dans get_work_program_count: {str(e)}", exc_info=True)
            return {
                'error': True,
                'message': str(e),
                'tasks_valid': 0
            }
            
    @http.route('/dashboard/work_program_to_validate', type='json', auth='user', methods=['POST'], csrf=False)
    def get_work_program_to_validate_count(self, date_from=None, date_to=None, department_id=None, responsible_id=None,project_id=None):
        """
        R√©cup√®re le nombre total de t√¢ches √† valider avec filtres date, d√©partement et responsable
        """
        try:
            _logger.info(
                f"D√©but de get_work_program_to_validate_count avec filtres: "
                f"date_from={date_from}, date_to={date_to}, dept={department_id}, resp={responsible_id}"
            )

            # R√©cup√©ration de toutes les t√¢ches
            tasks = request.env['work.program'].sudo().search([])
            _logger.info(f"Trouv√© {len(tasks)} t√¢ches au total")

            if not tasks:
                return {'tasks_to_validate': 0, 'error': False}

            # Pr√©paration des donn√©es dans une liste
            task_data_list = []
            for task in tasks:
                task_data_list.append({
                    'id': task.id,
                    'assignment_date': task.assignment_date if task.assignment_date else None,
                    'project_id': task.project_id.id if task.project_id else None,
                    'department_id': task.responsible_id.department_id.id if task.responsible_id and task.responsible_id.department_id else None,
                    'support_ids': [emp.id for emp in task.support_ids] if task.support_ids else [],
                    'responsible_id': task.responsible_id.id if task.responsible_id else None,
                    'state': task.state
                })

            df = pd.DataFrame(task_data_list)

            if df.empty:
                return {'tasks_to_validate': 0, 'error': False}
            
            df = self._apply_security_filter(df)

            # üîπ Filtrage des t√¢ches √† valider
            df_to_validate = df[df['state'] == 'to_validate']

            if df_to_validate.empty:
                _logger.info("Aucune t√¢che √† valider apr√®s filtrage")
                return {'tasks_to_validate': 0, 'error': False}

            # üîπ Application des filtres suppl√©mentaires
            filtered_df = self._apply_date_filters(df_to_validate, date_from, date_to, department_id, responsible_id,project_id)

            if filtered_df.empty:
                _logger.info("Aucune t√¢che √† valider apr√®s filtres suppl√©mentaires")
                return {'tasks_to_validate': 0, 'error': False}

            # üîπ Calcul final
            tasks_to_validate = len(filtered_df)
            _logger.info(f"Nombre de t√¢ches √† valider apr√®s filtres: {tasks_to_validate}")

            return {
                'tasks_to_validate': tasks_to_validate,
                'error': False
            }

        except Exception as e:
            _logger.error(f"Erreur dans get_work_program_to_validate_count: {str(e)}", exc_info=True)
            return {
                'error': True,
                'message': str(e),
                'tasks_to_validate': 0
            }
            
    @http.route('/dashboard/work_program_complexity_distribution', type='json', auth='user', methods=['POST'], csrf=False)
    def get_work_program_complexity_distribution(self, date_from=None, date_to=None, department_id=None, responsible_id=None,project_id=None):
        """
        R√©cup√®re la r√©partition des t√¢ches par complexit√© ('low', 'medium', 'high')
        avec les filtres date, d√©partement et responsable.
        """
        try:
            _logger.info(
                f"D√©but de get_work_program_complexity_distribution avec filtres: "
                f"date_from={date_from}, date_to={date_to}, dept={department_id}, resp={responsible_id}"
            )

            # üîπ R√©cup√©ration des t√¢ches
            tasks = request.env['work.program'].sudo().search([])
            _logger.info(f"Trouv√© {len(tasks)} t√¢ches au total")

            if not tasks:
                return {'complexity_data': {'labels': [], 'values': []}, 'error': False}

            # üîπ Pr√©paration du DataFrame
            task_data_list = []
            for task in tasks:
                task_data_list.append({
                    'id': task.id,
                    'assignment_date': task.assignment_date if task.assignment_date else None,
                    'project_id': task.project_id.id if task.project_id else None,
                    'department_id': task.responsible_id.department_id.id if task.responsible_id and task.responsible_id.department_id else None,
                    'responsible_id': task.responsible_id.id if task.responsible_id else None,
                    'support_ids': [emp.id for emp in task.support_ids] if task.support_ids else [],
                    'complexity': task.complexity,
                })

            df = pd.DataFrame(task_data_list)
            if df.empty:
                return {'complexity_data': {'labels': [], 'values': []}, 'error': False}
            
            df = self._apply_security_filter(df)

            # üîπ Application des filtres via ta fonction existante
            filtered_df = self._apply_date_filters(df, date_from, date_to, department_id, responsible_id,project_id)
            if filtered_df.empty:
                _logger.info("Aucune t√¢che apr√®s filtres")
                return {'complexity_data': {'labels': [], 'values': []}, 'error': False}

            # üîπ Ne garder que les valeurs valides
            valid_values = ['low', 'medium', 'high']
            df_valid = filtered_df[filtered_df['complexity'].isin(valid_values)]

            # üîπ Comptage par complexit√©
            complexity_counts = df_valid['complexity'].value_counts().reindex(valid_values, fill_value=0)

            complexity_data = {
                'labels': complexity_counts.index.tolist(),
                'values': complexity_counts.values.tolist()
            }

            _logger.info(f"R√©partition des complexit√©s: {complexity_data}")

            return {
                'complexity_data': complexity_data,
                'error': False
            }

        except Exception as e:
            _logger.error(f"Erreur dans get_work_program_complexity_distribution: {str(e)}", exc_info=True)
            return {
                'error': True,
                'message': str(e),
                'complexity_data': {'labels': [], 'values': []}
            }
            
    @http.route('/dashboard/work_program_priority_distribution', type='json', auth='user', methods=['POST'], csrf=False)
    def get_work_program_priority_distribution(self, date_from=None, date_to=None, department_id=None, responsible_id=None,project_id=None):
        """
        R√©cup√®re la r√©partition des t√¢ches par priorit√© ('low', 'medium', 'high')
        avec filtres date, d√©partement et responsable.
        """
        try:
            _logger.info(
                f"D√©but de get_work_program_priority_distribution avec filtres: "
                f"date_from={date_from}, date_to={date_to}, dept={department_id}, resp={responsible_id}"
            )

            # üîπ R√©cup√©ration des t√¢ches
            tasks = request.env['work.program'].sudo().search([])
            _logger.info(f"Trouv√© {len(tasks)} t√¢ches au total")

            if not tasks:
                return {'priority_data': {'labels': [], 'values': []}, 'error': False}

            # üîπ Pr√©paration du DataFrame
            task_data_list = []
            for task in tasks:
                task_data_list.append({
                    'id': task.id,
                    'assignment_date': task.assignment_date if task.assignment_date else None,
                    'project_id': task.project_id.id if task.project_id else None,
                    'department_id': task.responsible_id.department_id.id if task.responsible_id and task.responsible_id.department_id else None,
                    'responsible_id': task.responsible_id.id if task.responsible_id else None,
                    'support_ids': [emp.id for emp in task.support_ids] if task.support_ids else [],
                    'priority': task.priority,
                })

            df = pd.DataFrame(task_data_list)
            if df.empty:
                return {'priority_data': {'labels': [], 'values': []}, 'error': False}
            
            df = self._apply_security_filter(df)

            # üîπ Application des filtres via ta fonction existante
            filtered_df = self._apply_date_filters(df, date_from, date_to, department_id, responsible_id,project_id)
            if filtered_df.empty:
                _logger.info("Aucune t√¢che apr√®s filtres")
                return {'priority_data': {'labels': [], 'values': []}, 'error': False}

            # üîπ S√©lection des valeurs valides
            valid_values = ['low', 'medium', 'high']
            df_valid = filtered_df[filtered_df['priority'].isin(valid_values)]

            # üîπ Comptage par priorit√©
            priority_counts = df_valid['priority'].value_counts().reindex(valid_values, fill_value=0)

            priority_data = {
                'labels': priority_counts.index.tolist(),
                'values': priority_counts.values.tolist()
            }

            _logger.info(f"R√©partition des priorit√©s: {priority_data}")

            return {
                'priority_data': priority_data,
                'error': False
            }

        except Exception as e:
            _logger.error(f"Erreur dans get_work_program_priority_distribution: {str(e)}", exc_info=True)
            return {
                'error': True,
                'message': str(e),
                'priority_data': {'labels': [], 'values': []}
            }
            
    @http.route('/dashboard/work_program_state_distribution', type='json', auth='user', methods=['POST'], csrf=False)
    def get_work_program_state_distribution(self, date_from=None, date_to=None, department_id=None, responsible_id=None,project_id=None):
        """
        R√©cup√®re la r√©partition des t√¢ches par √©tat (sauf 'draft') avec filtres date, d√©partement et responsable.
        Tri√© du plus petit au plus grand.
        """
        try:
            _logger.info(
                f"D√©but de get_work_program_state_distribution avec filtres: "
                f"date_from={date_from}, date_to={date_to}, dept={department_id}, resp={responsible_id}"
            )

            # üîπ R√©cup√©ration des t√¢ches
            tasks = request.env['work.program'].sudo().search([])
            _logger.info(f"Trouv√© {len(tasks)} t√¢ches au total")

            if not tasks:
                return {'state_data': {'labels': [], 'values': []}, 'error': False}

            # üîπ Pr√©paration du DataFrame
            task_data_list = []
            for task in tasks:
                task_data_list.append({
                    'id': task.id,
                    'assignment_date': task.assignment_date if task.assignment_date else None,
                    'project_id': task.project_id.id if task.project_id else None,
                    'department_id': task.responsible_id.department_id.id if task.responsible_id and task.responsible_id.department_id else None,
                    'responsible_id': task.responsible_id.id if task.responsible_id else None,
                    'support_ids': [emp.id for emp in task.support_ids] if task.support_ids else [],
                    'state': task.state,
                })

            df = pd.DataFrame(task_data_list)
            if df.empty:
                return {'state_data': {'labels': [], 'values': []}, 'error': False}
            
            df = self._apply_security_filter(df)

            # üîπ Application des filtres
            filtered_df = self._apply_date_filters(df, date_from, date_to, department_id, responsible_id,project_id)
            if filtered_df.empty:
                _logger.info("Aucune t√¢che apr√®s filtres")
                return {'state_data': {'labels': [], 'values': []}, 'error': False}

            # üîπ √âtats valides et traduction en fran√ßais
            state_map = {
                'draft':'Brouillon',
                'ongoing': 'En cours',
                'to_validate': '√Ä valider',
                'validated': 'Valid√©',
                'refused': 'Refus√©',
                'to_redo': '√Ä refaire',
                'incomplete': 'Inachev√©',
                'done': 'Termin√©',
                'cancelled': 'Annul√©'
            }
            df_valid = filtered_df[filtered_df['state'].isin(state_map.keys())]

            # üîπ Comptage par √©tat et tri du plus petit au plus grand
            state_counts = df_valid['state'].value_counts().reindex(state_map.keys(), fill_value=0).sort_values()

            state_data = {
                'labels': [state_map[s] for s in state_counts.index.tolist()],
                'values': state_counts.values.tolist()
            }

            _logger.info(f"R√©partition des √©tats (tri√©e): {state_data}")

            return {
                'state_data': state_data,
                'error': False
            }

        except Exception as e:
            _logger.error(f"Erreur dans get_work_program_state_distribution: {str(e)}", exc_info=True)
            return {
                'error': True,
                'message': str(e),
                'state_data': {'labels': [], 'values': []}
            }


    @http.route('/dashboard/work_program_grid', type='json', auth='user', methods=['POST'], csrf=False)
    def get_work_program_grid(self, date_from=None, date_to=None, department_id=None, responsible_id=None,project_id=None):
        """
        Renvoie les donn√©es filtr√©es pour AG Grid :
        - Champs : projet, description, responsable, image, d√©partement, dates, √©tat, priorit√©, complexit√©
        - Applique les filtres date, d√©partement et responsable
        """
        try:
            _logger.info(
                f"D√©but de get_work_program_grid avec filtres: "
                f"date_from={date_from}, date_to={date_to}, dept={department_id}, resp={responsible_id}"
            )

            # üîπ R√©cup√©ration des t√¢ches
            tasks = request.env['work.program'].sudo().search([])
            _logger.info(f"Trouv√© {len(tasks)} t√¢ches au total")
            _logger.info(f"Valeurs de state trouv√©es : {set(task.state for task in tasks)}")
            _logger.info(f"Dates brutes : {[{'id': t.id, 'assignment_date': t.assignment_date, 'initial_deadline': t.initial_deadline, 'actual_deadline': t.actual_deadline} for t in tasks]}")

            if not tasks:
                return {'data': [], 'error': False}

            # üîπ Pr√©paration du DataFrame
            task_data_list = []
            for task in tasks:
                task_data_list.append({
                    'project': task.project_id.name if task.project_id else 'Non d√©fini',
                    'description': task.inputs_needed or '',
                    'responsible_display': task.responsible_id.name if task.responsible_id else 'Non d√©fini',
                    'responsible_image': f'/web/image/hr.employee/{task.responsible_id.id}/avatar_128' if task.responsible_id else '/web/static/src/img/placeholder.png',
                    'department_id': task.responsible_id.department_id.id if task.responsible_id and task.responsible_id.department_id else None,
                    'responsible_id': task.responsible_id.id if task.responsible_id else None,
                    'project_id': task.project_id.id if task.project_id else None,
                    'department_display': task.responsible_id.department_id.name if task.responsible_id and task.responsible_id.department_id else 'Non d√©fini',
                    'assignment_date': task.assignment_date if task.assignment_date else None,
                    'due_date': task.initial_deadline if task.initial_deadline else None,
                    'completion_date': task.actual_deadline if task.actual_deadline else None,
                    'priority': task.priority or 'unknown',
                    'complexity': task.complexity or 'unknown',
                    'support_ids': [emp.id for emp in task.support_ids] if task.support_ids else [],
                    'support_name': ', '.join(task.support_ids.mapped('name')) if task.support_ids else '',
                    'state': task.state or 'unknown'
                })

            df = pd.DataFrame(task_data_list)
            if df.empty:
                _logger.info("DataFrame vide apr√®s cr√©ation")
                return {'data': [], 'error': False}
            
            df = self._apply_security_filter(df)

            # üîπ Application des filtres
            filtered_df = self._apply_date_filters(df, date_from, date_to, department_id, responsible_id,project_id)
            _logger.info(f"T√¢ches apr√®s filtres : {len(filtered_df)}")
            
             # üîπ Conversion et tri par date d'assignation (plus r√©cente en premier)
            if 'assignment_date' in filtered_df.columns:
                filtered_df['assignment_date'] = pd.to_datetime(filtered_df['assignment_date'], errors='coerce')
                filtered_df = filtered_df.sort_values(
                    by='assignment_date',
                    ascending=False,
                    na_position='last'
                ).reset_index(drop=True)

            if filtered_df.empty:
                _logger.info("Aucune t√¢che apr√®s filtres")
                return {'data': [], 'error': False}

            # üîπ Formatage des donn√©es pour AG Grid
            grid_data = []
            for _, row in filtered_df.iterrows():
                grid_data.append({
                    'project': row['project'],
                    'description': row['description'],
                    'responsible_display': row['responsible_display'],
                    'responsible_image': row['responsible_image'],
                    'department_display': row['department_display'],
                    'support': row['support_name'],
                    'start_date': self.safe_date_format(row['assignment_date']),
                    'due_date': self.safe_date_format(row['due_date']),
                    'completion_date': self.safe_date_format(row['completion_date']),
                    'priority': row['priority'],
                    'complexity': row['complexity'],
                    'state': row['state']
                })

            _logger.info(f"Donn√©es renvoy√©es √† AG Grid apr√®s filtres: {len(grid_data)} lignes")

            return {
                'data': grid_data,
                'error': False
            }

        except Exception as e:
            _logger.error(f"Erreur dans get_work_program_grid: {str(e)}", exc_info=True)
            return {
                'data': [],
                'error': True,
                'message': str(e)
            }
            
    def _apply_date_filters(self, df, date_from, date_to, department_id, responsible_id,project_id=None):
        """Applique les filtres de date, d√©partement et responsable sur le DataFrame"""
        filtered_df = df.copy()

        # Filtrage par dates bas√© sur assignment_date
        if date_from or date_to:
            filtered_df['assignment_date'] = pd.to_datetime(filtered_df['assignment_date'], errors='coerce')
            
            if date_from:
                date_from_dt = pd.to_datetime(date_from)
                filtered_df = filtered_df[filtered_df['assignment_date'] >= date_from_dt]
            
            if date_to:
                date_to_dt = pd.to_datetime(date_to)
                filtered_df = filtered_df[filtered_df['assignment_date'] <= date_to_dt]

        # Filtrage par NOM du d√©partement (depuis hr.department)
        # ‚úÖ REMPLACER
        # if department_id is not None and department_id != "":
        #     try:
        #         dept_id = int(department_id)
        #         filtered_df = filtered_df[filtered_df['department_id'] == dept_id]
        #     except (ValueError, TypeError):
        #         _logger.warning(f"ID d√©partement invalide: {department_id}")
        
        if department_id is not None and department_id != "" and department_id != "null":
            try:
                dept_id = int(department_id)
                _logger.info(f"üîπ Filtre d√©partement appliqu√©: {dept_id}")
                filtered_df = filtered_df[filtered_df['department_id'] == dept_id]
            except (ValueError, TypeError):
                _logger.warning(f"ID d√©partement invalide: {department_id}")
        else:
            # ‚úÖ CRUCIAL : Quand department_id est None, on ne filtre PAS
            # Le DataFrame contient d√©j√† toutes les donn√©es sans filtre d√©partement
            _logger.info("üîπ Aucun filtre d√©partement appliqu√© (tous les d√©partements)")

        # Filtrage par responsable ou support
        if responsible_id is not None and responsible_id != "":
            responsible_id = int(responsible_id)
            filtered_df = filtered_df[
                (filtered_df['responsible_id'] == responsible_id) |
                (filtered_df['support_ids'].apply(lambda x: responsible_id in x if isinstance(x, list) else False))
            ]
        

        return filtered_df

    def safe_date_format(self, value):
        """Formate les dates pour l'affichage"""
        import datetime
        if value is None or value == '' or (isinstance(value, float) and pd.isna(value)):
            return ''
        if isinstance(value, bool):
            return ''
        if isinstance(value, (datetime.date, datetime.datetime)):
            return value.strftime('%Y-%m-%d')
        return str(value)